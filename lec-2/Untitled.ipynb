{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ramblings: Rejoinder a Regularización y Expansiones Basales\n",
    "\n",
    "\n",
    "## Diferencia entre MSE, RMSE, MAE\n",
    "\n",
    "- _Median Absolute Error_ $\\leadsto$ Magnitud promedio de los errores, agnóstica a la dirección.\n",
    "\n",
    "$$\n",
    "\\textsf{MAE} = \\frac{1}{n}\\sum_{j=1}^{n}\\vert y_{j} - \\hat{y}_{j} \\vert\n",
    "$$\n",
    "\n",
    "- _Median Squared Error y Root Median Squared Error_: Regla cuadrática que evalúa la función de pérdida en un plano de coordenadas\n",
    "\n",
    "$$\n",
    "\\textsf{MSE} = \\frac{1}{n}\\sum_{j=1}^{n}(y_{j} - \\hat{y}_{j})^{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textsf{RMSE} = \\sqrt{\\textsf{MSE}}\n",
    "$$\n",
    "\n",
    "MAE y RMSE expresan el error promedio en términos del vector objetivo, con un rango de $\\varepsilon\\rightarrow [0, \\infty^{+})$. Ambos son agnósticos a la dirección de los errores (RMSE preserva cardinalidad y evita suma cero mediante $\\sqrt{X}$ y MAE preserva cardinalidad mediante valor absoluto)\n",
    "\n",
    "MSE permite diagnosticar si las predicciones realizadas por el modelo subestiman o sobreestiman el comportamiento, dado su signo.\n",
    "\n",
    "#### Manual de Cortapalos en funciones de pérdida contínuas\n",
    "\n",
    "- Si MAE $>$ (R)MSE, significa que el punto equidistante de los errores es superior a la métrica promedio cuadrático. En esta situación, esperamos tener observaciones atípicas con __sobreestimaciones__. Esta situación puede ocurrir cuando nuestro modelo falla en identificar outliers. Esperamos tener una mayor concentración en valores bajos de la distribución del error\n",
    "\n",
    "- Si MAE $<$ (R)MSE, significa que el punto equidistante de los errores es superior a la métrica promedio cuadrático. En esta situación, esperamos tener observaciones atípicas con __subestimaciones__. Esta situación puede ocurrir cuando neustro modelo falla en identificar outliers. Esperamos tener una mayor concentración en valores altos de la distribución del error.\n",
    "\n",
    "- MSE permite reportar la sub/sobre estimación del modelo __respecto a la esperanza matemática del vector objetivo__. $\\mathbb{E}[y]$.\n",
    "\n",
    "\n",
    "## GLMNET: Modelos generalizados regularizados \n",
    "\n",
    "Los métodos vistos con `sklearn` por defecto implementan MCO. Se puede flexibilizar la familia estocástica a regularizar mediante GLMNET.\n",
    "\n",
    "https://web.stanford.edu/~hastie/glmnet_python/\n",
    "\n",
    "## Profundización en las variantes CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = make_regression(n_samples=1000,\n",
    "                           n_features=100,\n",
    "                           n_targets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_attr = StandardScaler().fit_transform(sim_data[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(std_attr,\n",
    "                                                   sim_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hiperparámetros relevantes del modelo:\n",
    "    - alphas: Rango de valores del contorno regularizador ($\\lambda$)\n",
    "    - cv: Cantidad de validaciones cruzadas.\n",
    "    - scoring:  https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    \n",
    "    \n",
    "* Podemos definir el rango de $\\lambda$ y la cantidad de regularizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas = [0.001, 0.01, 0.5, 1],\n",
    "                   cv=10,\n",
    "                   scoring=\"neg_mean_absolute_error\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* También podemos extraer la métrica específica en cada valor del hiperparámetro y una cantidad \"óptima\" de validaciones cruzadas inferidas mediante LOO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_auto_loo = RidgeCV(alphas = [0.001, 0.01, 0.5, 1],\n",
    "                           store_cv_values=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ver especificación de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphas': array([0.001, 0.01 , 0.5  , 1.   ]),\n",
       " 'cv': 10,\n",
       " 'fit_intercept': True,\n",
       " 'gcv_mode': None,\n",
       " 'normalize': False,\n",
       " 'scoring': 'neg_mean_absolute_error',\n",
       " 'store_cv_values': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.set_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos pedir el score (por defecto da $r^2$), puaj :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999693"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemento importante a considerar en un objeto creado con `sklearn`\n",
    "\n",
    "Aquellos elementos dentro del objeto que terminan con `_` representan a las instancias del objeto. Con ello podemos extraer información relevante sobre la ejecución del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.34402944e+01, -6.14154263e-06,  7.28066217e+00,  9.85499087e-06,\n",
       "       -5.58041870e-06,  8.93682686e-06, -1.53987795e-05,  6.22425674e-07,\n",
       "        1.01074851e-05,  1.38449345e-05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.coef_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instancias sin un underscore al final, representan parámetros ingresados en la __inicialización__ del método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.01 , 0.5  , 1.   ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por último, están los métodos dentro del objeto entrenado, en este caso debemos pasar argumentos :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-173.39166293,  191.44541724,  111.54307564,   18.55440881,\n",
       "       -115.86652988,   41.30496874,  205.83730278,  -33.33534837,\n",
       "        268.9704177 , -141.99077754])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* De manera adicional, cuando especificamos `store_cv_value=True` y `cv=None`, podemos extraer el valor de la métrica en toda la grilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.71315962e-08, 1.71306757e-06, 4.27016336e-03, 1.70297903e-02],\n",
       "       [2.82091427e-07, 2.82081183e-05, 7.03810820e-02, 2.80957925e-01],\n",
       "       [8.65685595e-09, 8.65658434e-07, 2.16045368e-03, 8.62677435e-03],\n",
       "       ...,\n",
       "       [1.74033229e-09, 1.74012355e-07, 4.32200571e-04, 1.71733820e-03],\n",
       "       [4.90908921e-07, 4.90889872e-05, 1.22463636e-01, 4.88801779e-01],\n",
       "       [6.04220415e-09, 6.04179124e-07, 1.50484101e-03, 5.99659007e-03]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_auto_loo.cv_values_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre las funciones de identidad en GAM\n",
    "\n",
    "* Retomemos el punto de Generalized Linear Models (jerga de Dobson, 2008; King, 1992):\n",
    "    - Componente estocástico: Proceso de Generación de Datos subyacente.\n",
    "    - Componente sistemático: Combinación lineal de parámetros.\n",
    "    - Función de enlace: Generalización de $g(\\mathbb{E}[y]) = \\mathbf{X}\\vec{\\beta}$\n",
    "    \n",
    "* Las funciones de enlace en el contexto de GLM tenían formas restringidas $\\leadsto$ $\\textsf{logit}(\\mu), \\textsf{log}(\\mu), 1/\\mu$.\n",
    "\n",
    "* En GAM, la función de identidad toma una forma aproximadamente \"no paramétrica\", tomando en consideración la distribución conjunta de los datos.\n",
    "\n",
    "* El método para esto se llama _Backfitting_ $\\leadsto$ \"Asumamos que $\\boldsymbol\\beta$ es no identificable, promediemos las observaciones en una ventana de Parzen, repitamos esto hasta que el valor de $\\boldsymbol\\beta$ se estabilice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencia parcial\n",
    "\n",
    "> Notación de Hastie et al. (2009)\n",
    "\n",
    "* Objetivo: identificar la naturaleza de la dependencia de nuestra función de identidad $f(X)$ en los valores conjuntos.\n",
    "    - Limitante: Funciona cuando nuestras dimensiones son bajas :(\n",
    "    \n",
    "* La dependencia parcial obtiene un subconjunto de atributos indexados en $\\mathcal{S} \\subset \\{1, 2, \\cdots, p\\}$.\n",
    "* Si una función general mapea $f(X)=f(X_{s}, X_{c})$, el __promedio de la dependencia parcial en el subconjunto de atributos será:__\n",
    "\n",
    "$$\n",
    "f_{\\mathcal{S}}(X_{\\mathcal{S}}) = \\mathbb{E}_{X_{c}}(X_{\\mathcal{S}}, X_{C})\n",
    "$$\n",
    "\n",
    "Los métodos de dependencia parcial permiten evaluar algoritmos \"de caja negra\" mediante:\n",
    "\n",
    "$$\n",
    "\\bar{f}_{\\mathcal{S}}(X_{\\mathcal{S}}) = \\frac{1}{N}\\sum_{i=1}^{N}f(X_{\\mathcal{S}}, x_{iC})\n",
    "$$\n",
    "\n",
    "De esta manera, los gráficos permite evaluar el efecto específico de una variable __después de considerar el efecto del resto de atributos controlado en las medias__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
